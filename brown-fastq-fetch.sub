# brown-fastq-fetch.sub
# Job submission to HTCondor to fetch fastq files via SRA-Toolkit
#
# Specify the HTCondor Universe (vanilla is the default and is used
#  for almost all jobs) and your desired name of the HTCondor log file,
#  which is where HTCondor will describe what steps it takes to run 
#  your job. Wherever you see $(Cluster), HTCondor will insert the 
#  queue number assigned to this set of jobs at the time of submission.
universe = vanilla
log = brown-fastq-fetch_$(Cluster).log
#
# Notification Settings
#
notification = Always
notify_user = wblashka@wisc.edu
#
# Specify use of transfer file staging area
#
requirements = (Target.HasCHTCStaging == True)
#
# Specify your executable (single binary or a script that runs several
#  commands), arguments, and a files for HTCondor to store standard
#  output (or "screen output").
#  $(Process) will be a integer number for each job, starting with "0"
#  and increasing for the relevant number of jobs.
executable = brown-fastq-fetch.sh
arguments = $(Process)
output = brown-fastq-fetch_$(Cluster)_$(Process).out
error = brown-fastq-fetch_$(Cluster)_$(Process).err
#
# Specify that HTCondor should transfer files to and from the
#  computer where each job runs. The last of these lines *would* be
#  used if there were any other files needed for the executable to use.
should_transfer_files = YES
when_to_transfer_output = ON_EXIT
# transfer_input_files = file1,/absolute/pathto/file2,etc
transfer_input_files = sra_list.csv, amazon-corretto-17-x64-linux-jdk.tar.gz
transfer_output_files = fastq_raw_reads.tar.gz, .nextflow.log
transfer_output_remaps = "fastq_raw_reads.tar.gz = file:///staging/groups/surgery_brown_group/fetchngs_CMs.tar.gz"
#
# Tell HTCondor what amount of compute resources
#  each job will need on the computer where it runs.
request_cpus = 1
request_memory = 16GB
request_disk = 768GB
#
# Tell HTCondor to run 1 instances of our job:
queue
